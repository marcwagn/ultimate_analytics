{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translating image coordinates to pitch coordinates with homography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating 4 corners of the pitch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Assumption 1: We have 4 corners of a sub-area, e.g. TLC-TRC-TLF-TRF\n",
    "- Assumption 2: Areas on the video are parallel, i.e. the camera stays in the centre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![perspective.png](perspective.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the top vertex of the triangle containing the projected view\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Union\n",
    "import numpy as np\n",
    "\n",
    "def calculate_intersection_of_lines(segment1: np.ndarray, segment2: np.ndarray) -> Union[Tuple[float, float], None]:\n",
    "    \"\"\"\n",
    "    Calculate intersection of lines defined by segments.\n",
    "    Reference: https://en.wikipedia.org/wiki/Line%E2%80%93line_intersection#Given_two_points_on_each_line\n",
    "    Return coordinates of a point of intersection, or None if lines defined by segments are parallel.\n",
    "    \"\"\"\n",
    "    if segment1.shape != (4,):\n",
    "        raise ValueError(\"segment1 must be a vector of size 4\")\n",
    "    if segment2.shape != (4,):\n",
    "        raise ValueError(\"segment2 must be a vector of size 4\")\n",
    "    x1, y1, x2, y2 = segment1[0], segment1[1], segment1[2], segment1[3]\n",
    "    x3, y3, x4, y4 = segment2[0], segment2[1], segment2[2], segment2[3]\n",
    "\n",
    "    def quarter_determinant(arr: np.ndarray) -> float:\n",
    "        \"\"\"Given a matrix of size 4x4, calculate a determinant of 4 determinants from each quarter\n",
    "        \"\"\"\n",
    "        if arr.shape != (4,4):\n",
    "            raise ValueError(\"arr must be a matrix of size 4x4\")\n",
    "        a1 = np.linalg.det(arr[0:2,0:2])\n",
    "        a2 = np.linalg.det(arr[0:2,2:4])\n",
    "        a3 = np.linalg.det(arr[2:4, 0:2])\n",
    "        a4 = np.linalg.det(arr[2:4, 2:4])\n",
    "        return np.linalg.det(np.array([[a1, a2], [a3, a4]]))\n",
    "\n",
    "    px_num = np.array([\n",
    "        [x1, y1, x1, 1],\n",
    "        [x2, y2, x2, 1],\n",
    "        [x3, y3, x3, 1],\n",
    "        [x4, y4, x4, 1]])\n",
    "    # px_div = np.array([\n",
    "    #     [x1, 1, y1, 1],\n",
    "    #     [x2, 1, y2, 1],\n",
    "    #     [x3, 1, y3, 1],\n",
    "    #     [x4, 1, y4, 1]])\n",
    "    py_num = np.array([\n",
    "        [x1, y1, y1, 1],\n",
    "        [x2, y2, y2, 1],\n",
    "        [x3, y3, y3, 1],\n",
    "        [x4, y4, y4, 1]])\n",
    "    pxy_div = np.array([\n",
    "        [x1, 1, y1, 1],\n",
    "        [x2, 1, y2, 1],\n",
    "        [x3, 1, y3, 1],\n",
    "        [x4, 1, y4, 1]])\n",
    "    \n",
    "    div_det = quarter_determinant(pxy_div)\n",
    "    if abs(div_det) < 0.00001:\n",
    "        # segment1 and segment2 seem to be parallel\n",
    "        return None\n",
    "    px = quarter_determinant(px_num)/div_det\n",
    "    py = quarter_determinant(py_num)/div_det\n",
    "    return px, py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:\n",
    "31 0.699563 0.102965 0.0109856 0.0191795 0.914857  #TRC\n",
    "31 0.342411 0.104897 0.00925484 0.0163508 0.699574 #TLC\n",
    "31 0.731543 0.135071 0.0102163 0.0179255 0.637236  #TRF\n",
    "31 0.310968 0.135658 0.00958964 0.0163189 0.448016  #TLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5242705938932326, -0.07301805160925191)\n"
     ]
    }
   ],
   "source": [
    "segment1 = np.array([0.310968, 0.135658, 0.342411, 0.104897])  #TLF-TLC\n",
    "segment2 = np.array([0.731543, 0.135071, 0.699563, 0.102965])  #TRF-TRC\n",
    "print(calculate_intersection_of_lines(segment1, segment2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find homography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 2)\n",
      "[[ 4.44144122e-03 -3.78778794e+00  1.17167545e+02]\n",
      " [ 5.61176098e-02 -1.74173122e+00  5.20352682e+01]\n",
      " [ 2.22072061e-05 -3.27443489e-02  1.00000000e+00]]\n",
      "[120.  80.   1.]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Define the corresponding points in the two images\n",
    "points1 = np.float32([[240, 17], [1, 20], [20, 30], [30, 30]])\n",
    "print(points1.shape)\n",
    "points2 = np.float32([[120, 80], [120, 50], [200, 50], [200, 80]])\n",
    "\n",
    "# Calculate the homography matrix\n",
    "H, mask = cv2.findHomography(points1, points2)\n",
    "\n",
    "print(H)\n",
    "pt = np.dot(H, np.float32([240, 17, 1]))\n",
    "pt = pt/pt[2]\n",
    "print(pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 322.98699566  330.14795874 -145.22583426]\n",
      " [  11.05894945 2044.36892089 -218.23487255]\n",
      " [   0.47978933   17.14012631    1.        ]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "#pitch_points = [[0.310968, 0.135658], [0.342411, 0.104897], [0.731543, 0.135071, 0.699563, 0.102965]]\n",
    "#src_points = np.array(cv2.Point2f\n",
    "src_points = np.array([[0.342411, 0.104897], [0.699563, 0.102965], [0.310968, 0.135658], [0.731543, 0.135071]])\n",
    "assert src_points.shape == (4,2)\n",
    "dst_points = np.array([[0,0],[37,0],[0,18],[37,18]])\n",
    "H, mask = cv2.findHomography(src_points, dst_points)\n",
    "print(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_h(H, vec):\n",
    "    pt = np.dot(H, vec)\n",
    "    return pt/pt[2]\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: [0.342411 0.104897 1.      ]; Tactical board: [-0.  0.  1.]\n",
      "Image: [0.699563 0.102965 1.      ]; Tactical board: [37.  0.  1.]\n",
      "Image: [0.310968 0.135658 1.      ]; Tactical board: [-0. 18.  1.]\n",
      "Image: [0.731543 0.135071 1.      ]; Tactical board: [37. 18.  1.]\n"
     ]
    }
   ],
   "source": [
    "vectors = np.float32([\n",
    "    [0.342411, 0.104897, 1],\n",
    "    [0.699563, 0.102965, 1],\n",
    "    [0.310968, 0.135658, 1],\n",
    "    [0.731543, 0.135071, 1]])\n",
    "for v in vectors[:,0:3]:\n",
    "    v2 = convert_h(H, v)\n",
    "    print(f\"Image: {v}; Tactical board: {convert_h(H, v)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tactical board: [0. 0. 1.]; Image: [0.34241101 0.104897   1.        ]\n",
      "Tactical board: [37.  0.  1.]; Image: [0.69956303 0.102965   1.        ]\n",
      "Tactical board: [ 0. 18.  1.]; Image: [0.31096801 0.135658   1.        ]\n",
      "Tactical board: [37. 18.  1.]; Image: [0.731543   0.13507099 1.        ]\n"
     ]
    }
   ],
   "source": [
    "H_inv = np.linalg.inv(H)\n",
    "assert H_inv.shape == (3,3)\n",
    "\n",
    "vectors2 = np.float32([[0,0,1],[37,0,1],[0,18,1],[37,18,1]])\n",
    "for v2 in vectors2[:,0:3]:\n",
    "    v1 = convert_h(H_inv, v2)\n",
    "    print(f\"Tactical board: {v2}; Image: {v1}\")\n",
    "#convert_h(H, vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[330. ]\n",
      " [265. ]\n",
      " [  1.5]]\n",
      "[[220.        ]\n",
      " [176.66666667]\n",
      " [  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "\n",
    "# # Define the homography matrix H\n",
    "# H = np.array([[1.4, 0.05, -100], [0.05, 1.5, -50], [0.001, 0.001, 1]])\n",
    "\n",
    "# # Define a point in the first image\n",
    "# point1 = np.array([[300], [200], [1]])\n",
    "# #point1 = np.array([300, 200, 1])\n",
    "\n",
    "# # Use the homography matrix to translate the point to the second image\n",
    "# point2 = np.dot(H, point1)\n",
    "# print(point2)\n",
    "# # Convert the point back to Cartesian coordinates\n",
    "# point2 = point2 / point2[2]\n",
    "\n",
    "# print(point2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now trying with coordinates beyond the initial image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pitch bottom line centre\n",
      "Translated to image coords: [1.75150574 1.15905296 1.        ] (may go beyond the normalized [[0,1],[0,1]]\n",
      "Translated back to tactical board, [ 37. 100.   1.]\n"
     ]
    }
   ],
   "source": [
    "print(\"Pitch bottom line centre on tactical board\")\n",
    "tactical_board_bottom_line_centre = np.float32([18.5, 100, 1])\n",
    "image_coords = convert_h(H_inv, tactical_board_bottom_line_centre)\n",
    "print(f\"Translated to image coords: {image_coords} (may go beyond the normalized [[0,1],[0,1]]\")\n",
    "print(f\"Translated back to tactical board, {convert_h(H, image_coords )}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image coords: [0. 0. 1.]; Tactical board coords: [-145.22583426 -218.23487255    1.        ]\n",
      "Image coords: [0. 1. 1.]; Tactical board coords: [ 10.19409244 100.66821022   1.        ]\n",
      "Image coords: [1. 0. 1.]; Tactical board coords: [ 120.12599206 -140.00366052    1.        ]\n",
      "Image coords: [1. 1. 1.]; Tactical board coords: [27.27773477 98.66816981  1.        ]\n"
     ]
    }
   ],
   "source": [
    "# Various corners of the original image, in the normalized coords\n",
    "img_corners = np.float32([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])\n",
    "for v in img_corners[:,0:3]:\n",
    "    print(f\"Image coords: {v}; Tactical board coords: {convert_h(H, v)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsrVideo1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
